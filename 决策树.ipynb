{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cd554b69e277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0moutlook_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "# 对原始数据进行分为训练数据和测试数据\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydotplus\n",
    "\n",
    "def outlook_type(s):\n",
    "    it = {'sunny':1, 'overcast':2, 'rainy':3}\n",
    "    return it[s]\n",
    "def temperature(s):\n",
    "    it = {'hot':1, 'mild':2, 'cool':3}\n",
    "    return it[s]\n",
    "def humidity(s):\n",
    "    it = {'high':1, 'normal':0}\n",
    "    return it[s]\n",
    "def windy(s):\n",
    "    it = {'TRUE':1, 'FALSE':0}\n",
    "    return it[s]\n",
    "\n",
    "def play_type(s):\n",
    "    it = {'yes': 1, 'no': 0}\n",
    "    return it[s]\n",
    "\n",
    "play_feature_E = 'outlook', 'temperature', 'humidity', 'windy'\n",
    "play_class = 'yes', 'no'\n",
    "\n",
    "# 1、读入数据，并将原始数据中的数据转换为数字形式\n",
    "data = np.loadtxt(\"play.tennies.txt\", delimiter=\" \", dtype=str,  converters={0:outlook_type, 1:temperature, 2:humidity, 3:windy,4:play_type})\n",
    "x, y = np.split(data,(4,),axis=1)\n",
    "\n",
    "# 2、拆分训练数据与测试数据，为了进行交叉验证\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "# 3、使用信息熵作为划分标准，对决策树进行训练\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "print(clf)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 4、把决策树结构写入文件\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=play_feature_E, class_names=play_class,\n",
    "                                filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf('play1.pdf')\n",
    "\n",
    "# 系数反映每个特征的影响力。越大表示该特征在分类中起到的作用越大\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "# 5、使用训练数据预测，预测结果完全正确\n",
    "answer = clf.predict(x_train)\n",
    "y_train = y_train.reshape(-1)\n",
    "print(answer)\n",
    "print(y_train)\n",
    "print(np.mean(answer == y_train))\n",
    "\n",
    "# 6、对测试数据进行预测，准确度较低，说明过拟合\n",
    "answer = clf.predict(x_test)\n",
    "y_test = y_test.reshape(-1)\n",
    "print(answer)\n",
    "print(y_test)\n",
    "print(np.mean(answer == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'treePlotter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ebfd97f2e8a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtreePlotter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'treePlotter'"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import treePlotter\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    #change to discrete values\n",
    "    return dataSet, labels\n",
    "\n",
    "##### 计算信息熵 ######\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)  # 样本数\n",
    "    labelCounts = {}   # 创建一个数据字典：key是最后一列的数值（即标签，也就是目标分类的类别），value是属于该类别的样本个数\n",
    "    for featVec in dataSet: # 遍历整个数据集，每次取一行\n",
    "        currentLabel = featVec[-1]  #取该行最后一列的值\n",
    "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0  # 初始化信息熵\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2) #log base 2  计算信息熵\n",
    "    return shannonEnt\n",
    "\n",
    "##### 按给定的特征划分数据 #########\n",
    "def splitDataSet(dataSet, axis, value): #axis是dataSet数据集下要进行特征划分的列号例如outlook是0列，value是该列下某个特征值，0列中的sunny\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet: #遍历数据集，并抽取按axis的当前value特征进划分的数据集(不包括axis列的值)\n",
    "        if featVec[axis] == value: #\n",
    "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "            # print axis,value,reducedFeatVec\n",
    "    # print retDataSet\n",
    "    return retDataSet\n",
    "\n",
    "##### 选取当前数据集下，用于划分数据集的最优特征\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1      #获取当前数据集的特征个数，最后一列是分类标签\n",
    "    baseEntropy = calcShannonEnt(dataSet)  #计算当前数据集的信息熵\n",
    "    bestInfoGain = 0.0; bestFeature = -1   #初始化最优信息增益和最优的特征\n",
    "    for i in range(numFeatures):        #遍历每个特征iterate over all the features\n",
    "        featList = [example[i] for example in dataSet]#获取数据集中当前特征下的所有值\n",
    "        uniqueVals = set(featList)       # 获取当前特征值，例如outlook下有sunny、overcast、rainy\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals: #计算每种划分方式的信息熵\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy     #计算信息增益\n",
    "        if (infoGain > bestInfoGain):       #比较每个特征的信息增益，只要最好的信息增益\n",
    "            bestInfoGain = infoGain         #if better than current best, set to best\n",
    "            bestFeature = i\n",
    "    return bestFeature                      #returns an integer\n",
    "#####该函数使用分类名称的列表，然后创建键值为classList中唯一值的数据字典。字典\n",
    "#####对象的存储了classList中每个类标签出现的频率。最后利用operator操作键值排序字典，\n",
    "#####并返回出现次数最多的分类名称\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "##### 生成决策树主方法\n",
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet] # 返回当前数据集下标签列所有值\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]#当类别完全相同时则停止继续划分，直接返回该类的标签\n",
    "    if len(dataSet[0]) == 1: ##遍历完所有的特征时，仍然不能将数据集划分成仅包含唯一类别的分组 dataSet\n",
    "        return majorityCnt(classList) #由于无法简单的返回唯一的类标签，这里就返回出现次数最多的类别作为返回值\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) # 获取最好的分类特征索引\n",
    "    bestFeatLabel = labels[bestFeat] #获取该特征的名字\n",
    "\n",
    "    # 这里直接使用字典变量来存储树信息，这对于绘制树形图很重要。\n",
    "    myTree = {bestFeatLabel:{}} #当前数据集选取最好的特征存储在bestFeat中\n",
    "    del(labels[bestFeat]) #删除已经在选取的特征\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
